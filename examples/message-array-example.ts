import 'dotenv/config';

import { createAgent, createStreamingAgent, calculatorTool, timestampTool } from '../src';
import type { CoreMessage } from '../src/types';

async function messageArrayExample() {
  console.log('ğŸ¤– OpenAgentic - Message Array Support Example\n');

  // =============================================================================
  // EXAMPLE 1: Standard Agent with Message Array
  // =============================================================================
  console.log('ğŸ“ Example 1: Standard Agent with Message Array');
  
  const agent = createAgent({
    model: 'gpt-4o-mini',
    tools: [calculatorTool, timestampTool],
    systemPrompt: 'You are a helpful assistant with access to tools.',
  });

  try {
    // Simulate a conversation history
    const conversationHistory: CoreMessage[] = [
      { role: 'system', content: 'You are a helpful assistant with access to tools.' },
      { role: 'user', content: 'Hello! What is 5 + 3?' },
      { role: 'assistant', content: 'I can help you with that calculation. Let me compute 5 + 3 for you.' },
      { role: 'user', content: 'Now also tell me what time it is and multiply the previous result by 2' }
    ];

    console.log('ğŸ”„ Executing with conversation history...');
    const result = await agent.execute(conversationHistory);
    
    console.log('âœ… Result with context:', result.result);
    console.log('ğŸ”§ Tools used:', result.toolCallsUsed);
    console.log('ğŸ“Š Iterations:', result.iterations);
  } catch (error) {
    console.error('âŒ Error:', error);
  }

  console.log('\n' + '='.repeat(80) + '\n');

  // =============================================================================
  // EXAMPLE 2: Compare String vs Message Array Input
  // =============================================================================
  console.log('ğŸ“ Example 2: Compare String vs Message Array Input');
  
  const comparisonAgent = createAgent({
    model: 'gpt-4o-mini',
    tools: [calculatorTool],
    systemPrompt: 'You are a math tutor.',
  });

  try {
    // Test with string input (original behavior)
    console.log('ğŸ”¤ Testing string input:');
    const stringResult = await comparisonAgent.execute('What is 12 * 8?');
    console.log('Result:', stringResult.result);
    
    // Reset for fresh state
    comparisonAgent.reset();
    
    // Test with message array (new behavior)
    console.log('\nğŸ“ Testing message array input:');
    const messageArray: CoreMessage[] = [
      { role: 'user', content: 'I need help with multiplication' },
      { role: 'assistant', content: 'I\'d be happy to help you with multiplication problems!' },
      { role: 'user', content: 'What is 12 * 8?' }
    ];
    
    const arrayResult = await comparisonAgent.execute(messageArray);
    console.log('Result:', arrayResult.result);
    
    console.log('\nğŸ“Š Comparison:');
    console.log('- String input provides no context');
    console.log('- Message array provides full conversation context');
    
  } catch (error) {
    console.error('âŒ Error:', error);
  }

  console.log('\n' + '='.repeat(80) + '\n');

  // =============================================================================
  // EXAMPLE 3: Streaming Agent with Message Array
  // =============================================================================
  console.log('ğŸ“ Example 3: Streaming Agent with Message Array');
  
  const streamingAgent = createStreamingAgent({
    model: 'claude-4-sonnet-20250514',
    tools: [calculatorTool, timestampTool],
    systemPrompt: 'You are a helpful streaming assistant.',
  });

  try {
    // Create a conversation with context
    const streamingMessages: CoreMessage[] = [
      { role: 'user', content: 'Hi, I\'m working on a math problem' },
      { role: 'assistant', content: 'I\'d be happy to help you with your math problem!' },
      { role: 'user', content: 'Calculate 15 * 24 and tell me the current time' }
    ];

    console.log('ğŸ”„ Streaming response with conversation context...\n');
    
    const stream = await streamingAgent.stream(streamingMessages);
    
    let content = '';
    for await (const chunk of stream.textStream) {
      content += chunk;
      process.stdout.write(chunk);
    }
    
    console.log('\n\nâœ… Streaming with message array completed');
    console.log('ğŸ“ Total content length:', content.length);
  } catch (error) {
    console.error('âŒ Streaming error:', error);
  }

  console.log('\n' + '='.repeat(80) + '\n');

  // =============================================================================
  // EXAMPLE 4: Complex Multi-Turn Conversation
  // =============================================================================
  console.log('ğŸ“ Example 4: Complex Multi-Turn Conversation');
  
  const conversationAgent = createAgent({
    model: 'gpt-4o-mini',
    tools: [calculatorTool, timestampTool],
    systemPrompt: 'You are a helpful assistant that remembers conversation context.',
  });

  try {
    // Build up a complex conversation
    const complexConversation: CoreMessage[] = [
      { role: 'user', content: 'I need to calculate some values for my project' },
      { role: 'assistant', content: 'I\'d be happy to help with calculations for your project!' },
      { role: 'user', content: 'First, what is 25 * 16?' },
      { role: 'assistant', content: 'Let me calculate that for you. 25 * 16 = 400.' },
      { role: 'user', content: 'Now take that result and divide it by 8, then tell me what time it is' }
    ];

    console.log('ğŸ”„ Processing complex conversation...');
    const result = await conversationAgent.execute(complexConversation);
    
    console.log('âœ… Complex conversation result:', result.result);
    console.log('ğŸ”§ Tools used:', result.toolCallsUsed);
    console.log('ğŸ’¬ Message history length:', result.messages.length);
  } catch (error) {
    console.error('âŒ Error:', error);
  }

  console.log('\n' + '='.repeat(80) + '\n');

  // =============================================================================
  // EXAMPLE 5: Message Array vs Direct API Comparison
  // =============================================================================
  console.log('ğŸ“ Example 5: Integration Pattern Example');
  
  try {
    // Simulate what would come from a chat application
    const chatMessages = [
      { role: 'user' as const, content: 'Hello' },
      { role: 'assistant' as const, content: 'Hi there! How can I help you?' },
      { role: 'user' as const, content: 'Calculate 7 * 9 and tell me the time' }
    ];

    // Convert to CoreMessage format (this is what convertToCoreMessages would do)
    const coreMessages: CoreMessage[] = chatMessages.map(msg => ({
      role: msg.role,
      content: msg.content
    }));

    const integrationAgent = createAgent({
      model: 'gpt-4o-mini',
      tools: [calculatorTool, timestampTool],
      systemPrompt: 'You are a helpful chat assistant.',
    });

    console.log('ğŸ”„ Processing chat messages directly...');
    const result = await integrationAgent.execute(coreMessages);
    
    console.log('âœ… Integration result:', result.result);
    console.log('ğŸ”§ Tools used:', result.toolCallsUsed);
    
    console.log('\nğŸ’¡ This pattern allows direct integration with AI SDK convertToCoreMessages()');
  } catch (error) {
    console.error('âŒ Error:', error);
  }

  console.log('\nğŸ‰ Message array support examples completed successfully!');
  console.log('\nğŸ’¡ Key Benefits:');
  console.log('- âœ… Full conversation context for better responses');
  console.log('- âœ… Backward compatibility with string inputs');
  console.log('- âœ… Direct AI SDK integration with convertToCoreMessages');
  console.log('- âœ… Better tool usage decisions based on context');
  console.log('- âœ… Support for multi-turn conversations');
}

if (require.main === module) {
  messageArrayExample().catch(console.error);
}